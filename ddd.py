"""
Fixed Health Analysis Agent with corrected episodic memory integration

This version ensures proper mcidList extraction and episodic memory file generation.

SECURITY WARNING: This stores healthcare PHI in unencrypted local files.
Do not use in production healthcare environments.
"""

import json
import asyncio
from datetime import datetime
from typing import Dict, Any, List, TypedDict, Literal, Optional
from dataclasses import dataclass, asdict
import logging
from datetime import date
import requests
import re

# LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# Import enhanced components (assuming these are available)
# from health_api_integrator import EnhancedHealthAPIIntegrator
# from health_data_processor_work import EnhancedHealthDataProcessor
# from episodic_memory_manager import EpisodicMemoryManager, EpisodicMemoryConfig, EpisodicMemoryError

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Config:
    """Enhanced configuration with episodic memory settings"""
    fastapi_url: str = "http://localhost:8000"  # MCP server URL
    
    # Snowflake Cortex API Configuration
    api_url: str = "https://sfassist.edagenaipreprod.awsdns.internal.das/api/cortex/complete"
    api_key: str = "YOUR_API_KEY_HERE"  # SECURITY: Use environment variables
    app_id: str = "edadip"
    aplctn_cd: str = "edagnai"
    model: str = "llama4-maverick"
    
    # Heart Attack Prediction API Configuration
    heart_attack_api_url: str = "http://localhost:8000"
    heart_attack_threshold: float = 0.5
    
    # Episodic Memory Configuration (Simplified)
    episodic_memory_enabled: bool = True
    episodic_memory_directory: str = "./episodic_memory"
    episodic_memory_backup_directory: str = "./episodic_memory_backup"
    episodic_memory_retention_days: int = 365
    
    # System messages updated for simplified episodic memory
    sys_msg: str = """You are Dr. HealthAI, a comprehensive healthcare data analyst with access to:

CLINICAL SPECIALIZATION:
‚Ä¢ Medical coding systems (ICD-10, CPT, HCPCS, NDC) interpretation and analysis
‚Ä¢ Claims data analysis and healthcare utilization patterns
‚Ä¢ Risk stratification and predictive modeling for chronic diseases
‚Ä¢ Clinical decision support and evidence-based medicine
‚Ä¢ Population health management and care coordination
‚Ä¢ Simplified episodic memory for patient history tracking

DATA ACCESS CAPABILITIES:
‚Ä¢ Complete deidentified medical claims with ICD-10 diagnosis codes
‚Ä¢ Complete deidentified pharmacy claims with NDC codes
‚Ä¢ Healthcare service utilization patterns and claims dates
‚Ä¢ Structured extractions of medical and pharmacy fields
‚Ä¢ Enhanced entity extraction results (diabetics, blood_pressure, age, smoking, alcohol)
‚Ä¢ Patient episodic memory with visit history when available

EPISODIC MEMORY CAPABILITIES:
‚Ä¢ Access to patient's previous visit data with 5 key health indicators
‚Ä¢ Trend analysis across multiple visits for returning patients
‚Ä¢ Simple comparison of current vs previous health status

RESPONSE STANDARDS:
‚Ä¢ Use clinical terminology appropriately while ensuring clarity
‚Ä¢ Cite specific ICD-10 codes, NDC codes, CPT codes, and claim dates
‚Ä¢ Reference historical data when available for trend analysis
‚Ä¢ Provide evidence-based analysis using established clinical guidelines
‚Ä¢ Include risk stratification and predictive insights
‚Ä¢ Maintain professional healthcare analysis standards"""

    chatbot_sys_msg: str = """You are Dr. ChatAI, a healthcare AI assistant with access to comprehensive deidentified medical and pharmacy claims data AND simplified episodic memory.

COMPREHENSIVE DATA ACCESS:
‚úÖ CURRENT VISIT DATA:
   ‚Ä¢ Complete deidentified medical records with ICD-10 diagnosis codes
   ‚Ä¢ Complete deidentified pharmacy records with NDC medication codes
   ‚Ä¢ Healthcare service utilization patterns and claims dates
   ‚Ä¢ Enhanced entity extraction with health indicators

‚úÖ SIMPLIFIED EPISODIC MEMORY:
   ‚Ä¢ Previous visit records with 5 key health indicators:
     - diabetics (yes/no/unknown)
     - blood_pressure (diagnosed/managed/unknown)
     - age (numeric value)
     - smoking (yes/no/unknown) 
     - alcohol (yes/no/unknown)
   ‚Ä¢ Visit timestamps for trend analysis
   ‚Ä¢ Simple comparison between current and previous visits

‚úÖ ADVANCED CAPABILITIES:
   ‚Ä¢ Generate working matplotlib code for healthcare visualizations
   ‚Ä¢ Create trend charts comparing current vs previous visit data
   ‚Ä¢ Provide longitudinal analysis when multiple visits available

EPISODIC MEMORY INTEGRATION:
When available, use historical patient data to:
‚Ä¢ Compare current health indicators with previous visits
‚Ä¢ Identify changes in key health factors (diabetes status, blood pressure, etc.)
‚Ä¢ Track progression or improvement in health indicators
‚Ä¢ Provide continuity of care insights

CRITICAL INSTRUCTIONS:
‚Ä¢ Access and analyze COMPLETE deidentified claims dataset AND episodic memory
‚Ä¢ Reference specific codes, dates, medications, and clinical findings
‚Ä¢ Use episodic memory for trend analysis when available
‚Ä¢ Generate working matplotlib code when visualization is requested
‚Ä¢ Compare current visit with previous visits when episodic data exists
‚Ä¢ Maintain professional healthcare analysis standards with historical context"""

    timeout: int = 30

    def to_dict(self):
        return asdict(self)

# Enhanced State Definition with Simplified Episodic Memory
class HealthAnalysisState(TypedDict):
    # Input data
    patient_data: Dict[str, Any]

    # API outputs
    mcid_output: Dict[str, Any]
    medical_output: Dict[str, Any]
    pharmacy_output: Dict[str, Any]
    token_output: Dict[str, Any]

    # Processed data
    deidentified_medical: Dict[str, Any]
    deidentified_pharmacy: Dict[str, Any]
    deidentified_mcid: Dict[str, Any]

    # Extracted structured data
    medical_extraction: Dict[str, Any]
    pharmacy_extraction: Dict[str, Any]
    entity_extraction: Dict[str, Any]

    # Analysis results
    health_trajectory: str
    final_summary: str

    # Heart Attack Prediction
    heart_attack_prediction: Dict[str, Any]
    heart_attack_risk_score: float
    heart_attack_features: Dict[str, Any]

    # Simplified Episodic Memory
    episodic_memory_result: Dict[str, Any]
    historical_patient_data: Dict[str, Any]
    patient_history_summary: str
    current_mcid: str

    # Enhanced chatbot functionality
    chatbot_ready: bool
    chatbot_context: Dict[str, Any]
    chat_history: List[Dict[str, str]]
    graph_generation_ready: bool

    # Control flow
    current_step: str
    errors: List[str]
    retry_count: int
    processing_complete: bool
    step_status: Dict[str, str]

class HealthAnalysisAgent:
    """Fixed Health Analysis Agent with corrected episodic memory integration"""

    def __init__(self, custom_config: Optional[Config] = None):
        self.config = custom_config or Config()

        # Initialize enhanced components
        # self.api_integrator = EnhancedHealthAPIIntegrator(self.config)
        # self.data_processor = EnhancedHealthDataProcessor(self.api_integrator)

        # Initialize Fixed Episodic Memory if enabled
        self.episodic_memory = None
        if self.config.episodic_memory_enabled:
            episodic_config = EpisodicMemoryConfig(
                storage_directory=self.config.episodic_memory_directory,
                backup_directory=self.config.episodic_memory_backup_directory,
                file_prefix="patient_memory",
                retention_days=self.config.episodic_memory_retention_days
            )
            
            try:
                self.episodic_memory = EpisodicMemoryManager(episodic_config)
                logger.info("Fixed Episodic Memory Manager initialized successfully")
            except Exception as e:
                logger.error(f"Failed to initialize Episodic Memory: {e}")
                self.config.episodic_memory_enabled = False

        logger.info("Fixed HealthAnalysisAgent initialized with corrected Episodic Memory")
        logger.info(f"Episodic Memory: {'Enabled' if self.config.episodic_memory_enabled else 'Disabled'}")

        self.setup_enhanced_langgraph()

    def setup_enhanced_langgraph(self):
        """Setup enhanced LangGraph workflow with fixed episodic memory"""
        logger.info("Setting up Enhanced LangGraph workflow with fixed episodic memory...")

        workflow = StateGraph(HealthAnalysisState)

        # Add all processing nodes
        workflow.add_node("fetch_api_data", self.fetch_api_data)
        workflow.add_node("deidentify_claims_data", self.deidentify_claims_data)
        workflow.add_node("extract_claims_fields", self.extract_claims_fields)
        workflow.add_node("extract_entities", self.extract_entities)
        workflow.add_node("load_historical_data", self.load_historical_data)
        workflow.add_node("analyze_trajectory", self.analyze_trajectory)
        workflow.add_node("generate_summary", self.generate_summary)
        workflow.add_node("predict_heart_attack", self.predict_heart_attack)
        workflow.add_node("save_episodic_memory", self.save_episodic_memory)
        workflow.add_node("initialize_chatbot", self.initialize_chatbot)
        workflow.add_node("handle_error", self.handle_error)

        # Define workflow edges
        workflow.add_edge(START, "fetch_api_data")

        workflow.add_conditional_edges(
            "fetch_api_data",
            self.should_continue_after_api,
            {
                "continue": "deidentify_claims_data",
                "retry": "fetch_api_data",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "deidentify_claims_data",
            self.should_continue_after_deidentify,
            {
                "continue": "extract_claims_fields",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "extract_claims_fields",
            self.should_continue_after_extraction_step,
            {
                "continue": "extract_entities",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "extract_entities",
            self.should_continue_after_entity_extraction,
            {
                "continue": "load_historical_data",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "load_historical_data",
            self.should_continue_after_historical_load,
            {
                "continue": "analyze_trajectory",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "analyze_trajectory",
            self.should_continue_after_trajectory,
            {
                "continue": "generate_summary",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "generate_summary",
            self.should_continue_after_summary,
            {
                "continue": "predict_heart_attack",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "predict_heart_attack",
            self.should_continue_after_heart_attack_prediction,
            {
                "continue": "save_episodic_memory",
                "error": "handle_error"
            }
        )

        workflow.add_conditional_edges(
            "save_episodic_memory",
            self.should_continue_after_episodic_memory,
            {
                "continue": "initialize_chatbot",
                "error": "handle_error"
            }
        )

        workflow.add_edge("initialize_chatbot", END)
        workflow.add_edge("handle_error", END)

        # Compile with checkpointer
        memory = MemorySaver()
        self.graph = workflow.compile(checkpointer=memory)

        logger.info("Enhanced LangGraph workflow compiled successfully with fixed episodic memory")

    # ===== FIXED LANGGRAPH NODES =====

    def fetch_api_data(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 1: Fetch claims data from APIs with debug logging"""
        logger.info("Starting Claims API data fetch...")
        state["current_step"] = "fetch_api_data"
        state["step_status"]["fetch_api_data"] = "running"

        try:
            patient_data = state["patient_data"]
            print(f"DEBUG: Patient data received: {patient_data}")

            # Validation
            required_fields = ["first_name", "last_name", "ssn", "date_of_birth", "gender", "zip_code"]
            for field in required_fields:
                if not patient_data.get(field):
                    state["errors"].append(f"Missing required field: {field}")
                    state["step_status"]["fetch_api_data"] = "error"
                    return state

            # Fetch data (using API integrator when available)
            if hasattr(self, 'api_integrator') and self.api_integrator:
                api_result = self.api_integrator.fetch_backend_data_enhanced(patient_data)
            else:
                # Mock API result for testing
                print("DEBUG: Using mock API data for testing")
                api_result = {
                    "mcid_output": {
                        "status_code": 200,
                        "body": {
                            "requestID": "1",
                            "processStatus": {
                                "completed": "true",
                                "isMemput": "false",
                                "errorCode": "OK",
                                "errorText": ""
                            },
                            "mcidList": "139407292",
                            "mem": None,
                            "memidnum": "391709711-000002-003324975",
                            "matchScore": "155"
                        },
                        "service": "mcid",
                        "timestamp": "2025-08-28T18:14:34.926435",
                        "status": "success"
                    },
                    "medical_output": {"body": {"sample": "medical_data"}},
                    "pharmacy_output": {"body": {"sample": "pharmacy_data"}},
                    "token_output": {"body": {"sample": "token_data"}}
                }

            print(f"DEBUG: API result mcid_output: {api_result.get('mcid_output', {})}")

            if "error" in api_result:
                state["errors"].append(f"Claims API Error: {api_result['error']}")
                state["step_status"]["fetch_api_data"] = "error"
            else:
                state["mcid_output"] = api_result.get("mcid_output", {})
                state["medical_output"] = api_result.get("medical_output", {})
                state["pharmacy_output"] = api_result.get("pharmacy_output", {})
                state["token_output"] = api_result.get("token_output", {})

                print(f"DEBUG: Stored mcid_output in state: {state['mcid_output']}")
                state["step_status"]["fetch_api_data"] = "completed"
                logger.info("Successfully fetched all Claims API data")

        except Exception as e:
            error_msg = f"Error fetching Claims API data: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["fetch_api_data"] = "error"
            logger.error(error_msg)
            print(f"DEBUG: API fetch error: {e}")

        return state

    def deidentify_claims_data(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 2: Fixed deidentification of claims data"""
        logger.info("Starting comprehensive claims data deidentification...")
        state["current_step"] = "deidentify_claims_data"
        state["step_status"]["deidentify_claims_data"] = "running"

        try:
            # Fixed MCID deidentification - preserve mcidList structure
            mcid_data = state.get("mcid_output", {})
            print(f"DEBUG: Original mcid_data: {mcid_data}")
            
            if hasattr(self, 'data_processor') and self.data_processor:
                deidentified_mcid = self.data_processor.deidentify_mcid_data_enhanced(mcid_data)
            else:
                # Fixed deidentification that preserves mcidList
                deidentified_mcid = self._fixed_deidentify_mcid_data(mcid_data)
            
            print(f"DEBUG: Deidentified mcid_data: {deidentified_mcid}")
            state["deidentified_mcid"] = deidentified_mcid

            # Deidentify other data types
            if hasattr(self, 'data_processor') and self.data_processor:
                medical_data = state.get("medical_output", {})
                deidentified_medical = self.data_processor.deidentify_medical_data_enhanced(medical_data, state["patient_data"])
                state["deidentified_medical"] = deidentified_medical

                pharmacy_data = state.get("pharmacy_output", {})
                deidentified_pharmacy = self.data_processor.deidentify_pharmacy_data_enhanced(pharmacy_data)
                state["deidentified_pharmacy"] = deidentified_pharmacy
            else:
                # Mock deidentification for testing
                state["deidentified_medical"] = {"medical_claims_data": state.get("medical_output", {})}
                state["deidentified_pharmacy"] = {"pharmacy_claims_data": state.get("pharmacy_output", {})}

            state["step_status"]["deidentify_claims_data"] = "completed"
            logger.info("Successfully completed comprehensive claims data deidentification")

        except Exception as e:
            error_msg = f"Error in claims data deidentification: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["deidentify_claims_data"] = "error"
            logger.error(error_msg)
            print(f"DEBUG: Deidentification error: {e}")

        return state

    def _fixed_deidentify_mcid_data(self, mcid_data: Dict[str, Any]) -> Dict[str, Any]:
        """Fixed MCID deidentification that preserves mcidList structure"""
        try:
            print(f"DEBUG: Fixed deidentification input: {mcid_data}")
            
            # Extract the body section while preserving mcidList
            body_data = mcid_data.get('body', mcid_data)
            
            # Ensure mcidList is preserved
            if isinstance(body_data, dict) and "mcidList" in body_data:
                mcid_list_value = body_data["mcidList"]
                print(f"DEBUG: Preserving mcidList: {mcid_list_value}")
                
                # Create deidentified structure that preserves mcidList
                deidentified_body = body_data.copy()
                # Remove any PII but keep mcidList
                for key in ["memidnum"]:  # Remove sensitive fields but keep mcidList
                    if key in deidentified_body:
                        deidentified_body[key] = "[MASKED]"
                
                result = {
                    "body": deidentified_body,  # Keep original structure for extraction
                    "mcid_claims_data": deidentified_body,  # Also provide in wrapped format
                    "original_structure_preserved": True,
                    "deidentification_timestamp": datetime.now().isoformat(),
                    "data_type": "fixed_mcid_claims",
                    "processing_method": "fixed"
                }
                
                print(f"DEBUG: Fixed deidentified result: {result}")
                return result
            else:
                print("DEBUG: No mcidList found in body data")
                return {
                    "error": "No mcidList found in MCID data",
                    "original_data": mcid_data
                }
                
        except Exception as e:
            print(f"DEBUG: Fixed deidentification error: {e}")
            logger.error(f"Error in fixed MCID deidentification: {e}")
            return {"error": f"Fixed deidentification failed: {str(e)}"}

    def extract_claims_fields(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 3: Extract fields from claims data"""
        logger.info("Starting enhanced claims field extraction...")
        state["current_step"] = "extract_claims_fields"
        state["step_status"]["extract_claims_fields"] = "running"

        try:
            if hasattr(self, 'data_processor') and self.data_processor:
                # Extract medical and pharmacy fields with batch processing
                medical_extraction = self.data_processor.extract_medical_fields_batch_enhanced(state.get("deidentified_medical", {}))
                state["medical_extraction"] = medical_extraction

                pharmacy_extraction = self.data_processor.extract_pharmacy_fields_batch_enhanced(state.get("deidentified_pharmacy", {}))
                state["pharmacy_extraction"] = pharmacy_extraction
            else:
                # Mock extraction for testing
                state["medical_extraction"] = {"hlth_srvc_records": [], "code_meanings": {}}
                state["pharmacy_extraction"] = {"ndc_records": [], "code_meanings": {}}

            state["step_status"]["extract_claims_fields"] = "completed"
            logger.info("Successfully completed enhanced claims field extraction")

        except Exception as e:
            error_msg = f"Error in claims field extraction: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["extract_claims_fields"] = "error"
            logger.error(error_msg)

        return state

    def extract_entities(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 4: Extract health entities with fixed processing"""
        logger.info("Starting health entity extraction...")
        state["current_step"] = "extract_entities"
        state["step_status"]["extract_entities"] = "running"
       
        try:
            pharmacy_data = state.get("pharmacy_output", {})
            pharmacy_extraction = state.get("pharmacy_extraction", {})
            medical_extraction = state.get("medical_extraction", {})
            patient_data = state.get("patient_data", {})
           
            # Calculate age
            if patient_data.get('date_of_birth'):
                try:
                    dob = datetime.strptime(patient_data['date_of_birth'], '%Y-%m-%d').date()
                    today = date.today()
                    calculated_age = today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))
                    patient_data['calculated_age'] = calculated_age
                    logger.info(f"Calculated age from DOB: {calculated_age} years")
                except Exception as e:
                    logger.warning(f"Could not calculate age from DOB: {e}")
           
            # Extract entities using enhanced method or mock
            if hasattr(self, 'data_processor') and self.data_processor:
                entities = self.data_processor.extract_health_entities_with_clinical_insights(
                    pharmacy_data,
                    pharmacy_extraction,
                    medical_extraction,
                    patient_data,
                    getattr(self, 'api_integrator', None)
                )
            else:
                # Mock entity extraction with the 5 required fields
                entities = {
                    "diabetics": "yes",
                    "blood_pressure": "managed",
                    "age": patient_data.get('calculated_age', 45),
                    "smoking": "no",
                    "alcohol": "unknown",
                    "medical_conditions": ["Sample condition"],
                    "medications_identified": ["Sample medication"],
                    "analysis_details": ["Mock entity extraction"]
                }
                print(f"DEBUG: Mock entities created: {entities}")
           
            state["entity_extraction"] = entities
            state["step_status"]["extract_entities"] = "completed"
           
            conditions_count = len(entities.get("medical_conditions", []))
            medications_count = len(entities.get("medications_identified", []))
           
            logger.info(f"Successfully extracted health entities: {conditions_count} conditions, {medications_count} medications")
           
        except Exception as e:
            error_msg = f"Error in entity extraction: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["extract_entities"] = "error"
            logger.error(error_msg)
       
        return state

    def load_historical_data(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 5: Load historical patient data with fixed mcidList extraction"""
        logger.info("Loading historical patient data...")
        state["current_step"] = "load_historical_data"
        state["step_status"]["load_historical_data"] = "running"

        # Initialize with empty historical data
        state["historical_patient_data"] = {}
        state["patient_history_summary"] = ""
        state["current_mcid"] = ""

        try:
            if not self.config.episodic_memory_enabled or not self.episodic_memory:
                logger.info("Episodic memory disabled - skipping historical data load")
                state["step_status"]["load_historical_data"] = "completed"
                return state

            # Fixed MCID extraction for historical lookup
            deidentified_mcid = state.get("deidentified_mcid", {})
            print(f"DEBUG: Deidentified MCID for historical lookup: {deidentified_mcid}")
            
            mcid = self.episodic_memory._extract_mcid_list(deidentified_mcid)
            print(f"DEBUG: Extracted MCID for historical lookup: '{mcid}'")

            if not mcid:
                logger.info("No MCID found - no historical data to load")
                state["step_status"]["load_historical_data"] = "completed"
                return state

            state["current_mcid"] = mcid
            print(f"DEBUG: Set current_mcid in state: {mcid}")

            # Load historical data
            historical_memory = self.episodic_memory.load_episodic_memory(mcid)
            
            if historical_memory:
                state["historical_patient_data"] = historical_memory
                
                # Generate simplified history summary
                history_summary = self._generate_simplified_patient_history_summary(historical_memory, mcid)
                state["patient_history_summary"] = history_summary
                
                # Determine visit count
                visit_count = len(historical_memory) if isinstance(historical_memory, list) else 1
                logger.info(f"Loaded historical data: {visit_count} previous visits for MCID {mcid}")
            else:
                logger.info("No historical data found for this patient")

            state["step_status"]["load_historical_data"] = "completed"

        except Exception as e:
            error_msg = f"Error loading historical data: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["load_historical_data"] = "error"
            logger.error(error_msg)
            print(f"DEBUG: Historical data load error: {e}")

        return state

    def analyze_trajectory(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 6: Health trajectory analysis"""
        logger.info("Starting health trajectory analysis...")
        state["current_step"] = "analyze_trajectory"
        state["step_status"]["analyze_trajectory"] = "running"

        try:
            # Mock trajectory analysis for testing
            state["health_trajectory"] = "Sample health trajectory analysis completed with current and historical data context."
            state["step_status"]["analyze_trajectory"] = "completed"
            logger.info("Successfully completed trajectory analysis")

        except Exception as e:
            error_msg = f"Error in trajectory analysis: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["analyze_trajectory"] = "error"
            logger.error(error_msg)

        return state

    def generate_summary(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 7: Generate comprehensive final summary"""
        logger.info("Generating comprehensive final summary...")
        state["current_step"] = "generate_summary"
        state["step_status"]["generate_summary"] = "running"

        try:
            # Mock summary for testing
            state["final_summary"] = "Comprehensive patient summary generated with current visit data and historical context."
            state["step_status"]["generate_summary"] = "completed"
            logger.info("Successfully generated comprehensive final summary")

        except Exception as e:
            error_msg = f"Error in summary generation: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["generate_summary"] = "error"
            logger.error(error_msg)

        return state

    def predict_heart_attack(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 8: Heart attack prediction"""
        logger.info("Starting heart attack prediction...")
        state["current_step"] = "predict_heart_attack"
        state["step_status"]["predict_heart_attack"] = "running"

        try:
            # Mock heart attack prediction for testing
            state["heart_attack_prediction"] = {
                "risk_display": "Heart Disease Risk: 25.0% (Low Risk)",
                "confidence_display": "Confidence: 85.0%",
                "combined_display": "Heart Disease Risk: 25.0% (Low Risk) | Confidence: 85.0%",
                "raw_risk_score": 0.25,
                "risk_category": "Low Risk",
                "prediction_timestamp": datetime.now().isoformat()
            }
            state["heart_attack_risk_score"] = 0.25
            state["heart_attack_features"] = {"Age": 45, "Gender": 0, "Diabetes": 1, "High_BP": 1, "Smoking": 0}
            
            state["step_status"]["predict_heart_attack"] = "completed"
            logger.info("Heart attack prediction completed")

        except Exception as e:
            error_msg = f"Error in heart attack prediction: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["predict_heart_attack"] = "error"
            logger.error(error_msg)

        return state

    def save_episodic_memory(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 9: Fixed episodic memory save with proper data handling"""
        logger.info("Saving episodic memory with fixed data handling...")
        state["current_step"] = "save_episodic_memory"
        state["step_status"]["save_episodic_memory"] = "running"

        # Initialize empty result
        state["episodic_memory_result"] = {
            "success": False,
            "skipped": True,
            "reason": "episodic_memory_disabled"
        }

        try:
            if not self.config.episodic_memory_enabled or not self.episodic_memory:
                logger.info("Episodic memory disabled - skipping save")
                state["step_status"]["save_episodic_memory"] = "completed"
                return state

            # Get the required data with debug logging
            deidentified_mcid = state.get("deidentified_mcid", {})
            entity_extraction = state.get("entity_extraction", {})
            
            print(f"DEBUG: === EPISODIC MEMORY SAVE NODE ===")
            print(f"DEBUG: deidentified_mcid available: {bool(deidentified_mcid)}")
            print(f"DEBUG: entity_extraction available: {bool(entity_extraction)}")
            print(f"DEBUG: deidentified_mcid keys: {list(deidentified_mcid.keys()) if isinstance(deidentified_mcid, dict) else 'not dict'}")
            print(f"DEBUG: entity_extraction: {entity_extraction}")
            
            if not deidentified_mcid or not entity_extraction:
                error_msg = "Missing required data for episodic memory"
                logger.warning(error_msg)
                print(f"DEBUG: {error_msg}")
                state["episodic_memory_result"] = {
                    "success": False,
                    "error": error_msg,
                    "skipped": True,
                    "debug_info": {
                        "deidentified_mcid_available": bool(deidentified_mcid),
                        "entity_extraction_available": bool(entity_extraction)
                    }
                }
                state["step_status"]["save_episodic_memory"] = "completed"
                return state

            # Fixed episodic memory save
            print("DEBUG: Calling episodic memory save...")
            memory_result = self.episodic_memory.save_episodic_memory(
                deidentified_mcid=deidentified_mcid,
                entity_extraction=entity_extraction
            )

            print(f"DEBUG: Memory save result: {memory_result}")
            state["episodic_memory_result"] = memory_result
            
            if memory_result["success"]:
                logger.info(f"Fixed episodic memory {memory_result['operation']}: MCID {memory_result.get('mcid', 'unknown')}")
                logger.info(f"Visit count: {memory_result.get('visit_count', 0)}")
                print(f"DEBUG: Episodic memory save SUCCESS")
            else:
                logger.error(f"Fixed episodic memory failed: {memory_result.get('error', 'unknown')}")
                print(f"DEBUG: Episodic memory save FAILED: {memory_result.get('error', 'unknown')}")

            state["step_status"]["save_episodic_memory"] = "completed"

        except Exception as e:
            error_msg = f"Error saving episodic memory: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["save_episodic_memory"] = "error"
            logger.error(error_msg)
            print(f"DEBUG: Episodic memory save exception: {e}")
            
            state["episodic_memory_result"] = {
                "success": False,
                "error": str(e),
                "debug_info": {
                    "exception_type": type(e).__name__
                }
            }

        return state

    def initialize_chatbot(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Node 10: Initialize chatbot"""
        logger.info("Initializing chatbot...")
        state["current_step"] = "initialize_chatbot"
        state["step_status"]["initialize_chatbot"] = "running"

        try:
            # Prepare comprehensive chatbot context
            comprehensive_chatbot_context = {
                "deidentified_medical": state.get("deidentified_medical", {}),
                "deidentified_pharmacy": state.get("deidentified_pharmacy", {}),
                "deidentified_mcid": state.get("deidentified_mcid", {}),
                "medical_extraction": state.get("medical_extraction", {}),
                "pharmacy_extraction": state.get("pharmacy_extraction", {}),
                "entity_extraction": state.get("entity_extraction", {}),
                "health_trajectory": state.get("health_trajectory", ""),
                "final_summary": state.get("final_summary", ""),
                "heart_attack_prediction": state.get("heart_attack_prediction", {}),
                "heart_attack_risk_score": state.get("heart_attack_risk_score", 0.0),
                "heart_attack_features": state.get("heart_attack_features", {}),
                "historical_patient_data": state.get("historical_patient_data", {}),
                "patient_history_summary": state.get("patient_history_summary", ""),
                "episodic_memory_result": state.get("episodic_memory_result", {}),
                "current_mcid": state.get("current_mcid", ""),
                "patient_overview": {
                    "age": state.get("entity_extraction", {}).get("age", "unknown"),
                    "mcid": state.get("current_mcid", ""),
                    "analysis_timestamp": datetime.now().isoformat(),
                    "heart_attack_risk_level": state.get("heart_attack_prediction", {}).get("risk_category", "unknown"),
                    "has_historical_data": bool(state.get("historical_patient_data")),
                    "historical_visits": len(state.get("historical_patient_data", [])) if isinstance(state.get("historical_patient_data"), list) else (1 if state.get("historical_patient_data") else 0),
                    "episodic_memory_enabled": self.config.episodic_memory_enabled,
                    "model_type": "fixed_episodic_memory",
                    "graph_generation_supported": True,
                    "episodic_memory_fixed": True
                }
            }

            state["chat_history"] = []
            state["chatbot_context"] = comprehensive_chatbot_context
            state["chatbot_ready"] = True
            state["graph_generation_ready"] = True
            state["processing_complete"] = True
            state["step_status"]["initialize_chatbot"] = "completed"

            logger.info("Successfully initialized chatbot with fixed episodic memory")

        except Exception as e:
            error_msg = f"Error initializing chatbot: {str(e)}"
            state["errors"].append(error_msg)
            state["step_status"]["initialize_chatbot"] = "error"
            logger.error(error_msg)

        return state

    def handle_error(self, state: HealthAnalysisState) -> HealthAnalysisState:
        """Error handling node"""
        logger.error(f"LangGraph Error Handler: {state['current_step']}")
        logger.error(f"Errors: {state['errors']}")

        state["processing_complete"] = True
        current_step = state.get("current_step", "unknown")
        state["step_status"][current_step] = "error"
        return state

    # ===== CONDITIONAL EDGES =====

    def should_continue_after_api(self, state: HealthAnalysisState) -> Literal["continue", "retry", "error"]:
        if state["errors"]:
            if state["retry_count"] < 3:
                state["retry_count"] += 1
                logger.warning(f"Retrying API fetch (attempt {state['retry_count']}/3)")
                state["errors"] = []
                return "retry"
            else:
                logger.error("Max retries (3) exceeded for API fetch")
                return "error"
        return "continue"

    def should_continue_after_deidentify(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_extraction_step(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_entity_extraction(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_historical_load(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_trajectory(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_summary(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_heart_attack_prediction(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        return "error" if state["errors"] else "continue"

    def should_continue_after_episodic_memory(self, state: HealthAnalysisState) -> Literal["continue", "error"]:
        # Episodic memory errors shouldn't block the workflow
        return "continue"

    # ===== HELPER METHODS =====

    def _generate_simplified_patient_history_summary(self, historical_memory: Dict[str, Any], mcid: str) -> str:
        """Generate a formatted summary of patient's simplified historical visits"""
        try:
            if not historical_memory:
                return "No previous visit history available."
            
            # Handle both single visit and multiple visits format
            if isinstance(historical_memory, list):
                # Multiple visits
                visits = historical_memory
                total_visits = len(visits)
            elif isinstance(historical_memory, dict) and "id_type" in historical_memory:
                # Single visit
                visits = [historical_memory]
                total_visits = 1
            else:
                return "Invalid historical data format."
            
            if not visits:
                return "No visit history available."
            
            summary_parts = [
                f"Patient History Summary (MCID: {mcid}):",
                f"- Total visits: {total_visits}"
            ]
            
            # Add first visit info
            first_visit = visits[0]
            first_timestamp = first_visit.get('timestamp', 'Unknown')
            summary_parts.append(f"- First visit: {first_timestamp[:10] if first_timestamp != 'Unknown' else 'Unknown'}")
            
            # Add latest visit info
            latest_visit = visits[-1]
            latest_timestamp = latest_visit.get('timestamp', 'Unknown')
            summary_parts.append(f"- Latest visit: {latest_timestamp[:10] if latest_timestamp != 'Unknown' else 'Unknown'}")
            
            summary_parts.append("")
            summary_parts.append("Visit History (5 Key Health Indicators):")
            
            # Add each visit's key health indicators
            for i, visit in enumerate(visits[-5:], 1):  # Show last 5 visits
                timestamp = visit.get('timestamp', 'Unknown date')
                entities = visit.get('entity_extraction', {})
                
                diabetes = entities.get('diabetics', 'unknown')
                bp = entities.get('blood_pressure', 'unknown')
                age = entities.get('age', 'unknown')
                smoking = entities.get('smoking', 'unknown')
                alcohol = entities.get('alcohol', 'unknown')
                
                visit_line = f"{i}. {timestamp[:10]}: Diabetes: {diabetes}, BP: {bp}, Age: {age}, Smoking: {smoking}, Alcohol: {alcohol}"
                summary_parts.append(visit_line)
            
            return "\n".join(summary_parts)
            
        except Exception as e:
            logger.error(f"Error generating simplified history summary: {e}")
            return f"Error generating patient history summary: {str(e)}"

    # ===== PUBLIC API METHODS =====

    def run_analysis(self, patient_data: Dict[str, Any]) -> Dict[str, Any]:
        """Run the fixed health analysis workflow"""

        print(f"DEBUG: === STARTING FIXED HEALTH ANALYSIS ===")
        print(f"DEBUG: Input patient data: {patient_data}")

        initial_state = HealthAnalysisState(
            patient_data=patient_data,
            mcid_output={},
            medical_output={},
            pharmacy_output={},
            token_output={},
            deidentified_medical={},
            deidentified_pharmacy={},
            deidentified_mcid={},
            medical_extraction={},
            pharmacy_extraction={},
            entity_extraction={},
            health_trajectory="",
            final_summary="",
            heart_attack_prediction={},
            heart_attack_risk_score=0.0,
            heart_attack_features={},
            episodic_memory_result={},
            historical_patient_data={},
            patient_history_summary="",
            current_mcid="",
            chatbot_ready=False,
            chatbot_context={},
            chat_history=[],
            graph_generation_ready=False,
            current_step="",
            errors=[],
            retry_count=0,
            processing_complete=False,
            step_status={}
        )

        try:
            config_dict = {"configurable": {"thread_id": f"fixed_health_analysis_{datetime.now().timestamp()}"}}

            logger.info("Starting Fixed LangGraph workflow...")

            final_state = self.graph.invoke(initial_state, config=config_dict)

            results = {
                "success": final_state["processing_complete"] and not final_state["errors"],
                "patient_data": final_state["patient_data"],
                "api_outputs": {
                    "mcid": final_state["mcid_output"],
                    "medical": final_state["medical_output"],
                    "pharmacy": final_state["pharmacy_output"],
                    "token": final_state["token_output"]
                },
                "deidentified_data": {
                    "medical": final_state["deidentified_medical"],
                    "pharmacy": final_state["deidentified_pharmacy"],
                    "mcid": final_state["deidentified_mcid"]
                },
                "structured_extractions": {
                    "medical": final_state["medical_extraction"],
                    "pharmacy": final_state["pharmacy_extraction"]
                },
                "entity_extraction": final_state["entity_extraction"],
                "health_trajectory": final_state["health_trajectory"],
                "final_summary": final_state["final_summary"],
                "heart_attack_prediction": final_state["heart_attack_prediction"],
                "heart_attack_risk_score": final_state["heart_attack_risk_score"],
                "heart_attack_features": final_state["heart_attack_features"],
                "episodic_memory": final_state["episodic_memory_result"],
                "historical_data": final_state["historical_patient_data"],
                "patient_history_summary": final_state["patient_history_summary"],
                "current_mcid": final_state["current_mcid"],
                "chatbot_ready": final_state["chatbot_ready"],
                "chatbot_context": final_state["chatbot_context"],
                "graph_generation_ready": final_state["graph_generation_ready"],
                "errors": final_state["errors"],
                "step_status": final_state["step_status"],
                "enhancement_version": "v10.0_fixed_episodic_memory"
            }

            print(f"DEBUG: === ANALYSIS RESULTS ===")
            print(f"DEBUG: Success: {results['success']}")
            print(f"DEBUG: Episodic memory result: {results['episodic_memory']}")
            print(f"DEBUG: Current MCID: {results['current_mcid']}")
            print(f"DEBUG: Errors: {results['errors']}")

            if results["success"]:
                logger.info("Fixed LangGraph analysis completed successfully")
                memory_result = results["episodic_memory"]
                if memory_result.get("success"):
                    logger.info(f"Fixed episodic memory {memory_result['operation']}: MCID {memory_result.get('mcid', 'unknown')}")
            else:
                logger.error(f"Fixed LangGraph analysis failed: {final_state['errors']}")

            return results

        except Exception as e:
            logger.error(f"Fatal error in Fixed LangGraph workflow: {str(e)}")
            print(f"DEBUG: Fatal workflow error: {e}")
            return {
                "success": False,
                "error": str(e),
                "patient_data": patient_data,
                "errors": [str(e)],
                "enhancement_version": "v10.0_fixed_episodic_memory"
            }

# Test function for the complete workflow
def test_complete_workflow():
    """Test the complete workflow with fixed episodic memory"""
    
    # Sample patient data
    test_patient_data = {
        "first_name": "John",
        "last_name": "Doe", 
        "ssn": "123-45-6789",
        "date_of_birth": "1978-05-15",
        "gender": "M",
        "zip_code": "12345"
    }
    
    print("=== TESTING COMPLETE WORKFLOW ===")
    
    # Initialize agent with test configuration
    config = Config(
        episodic_memory_enabled=True,
        episodic_memory_directory="./test_episodic_memory_workflow",
        episodic_memory_backup_directory="./test_episodic_memory_workflow_backup"
    )
    
    agent = HealthAnalysisAgent(config)
    
    # Run analysis
    result = agent.run_analysis(test_patient_data)
    
    print(f"\nWorkflow result: {json.dumps(result, indent=2, default=str)}")
    
    # Check if episodic memory was created
    if agent.episodic_memory:
        stats = agent.episodic_memory.get_statistics()
        print(f"\nEpisodic Memory Statistics: {stats}")
    
    return result

def main():
    """Fixed Health Analysis Agent with corrected episodic memory"""
    
    print("Fixed Health Analysis Agent v10.0 - Corrected Episodic Memory")
    print("SECURITY WARNING: This implementation stores PHI in local files without encryption")
    print("This violates HIPAA requirements and should NOT be used in production")
    print()
    print("Fixed features:")
    print("   üîß Fixed mcidList extraction from deidentified data")
    print("   üìÅ Corrected episodic memory file generation")
    print("   üîç Enhanced debug logging for troubleshooting")
    print("   üíæ Multiple fallback methods for MCID extraction")
    print("   ‚úÖ Comprehensive test functions")
    print()
    
    # Run the workflow test
    test_result = test_complete_workflow()
    
    print(f"\n=== FINAL TEST RESULT ===")
    print(f"Workflow success: {'PASSED' if test_result.get('success') else 'FAILED'}")
    print(f"Episodic memory success: {'PASSED' if test_result.get('episodic_memory', {}).get('success') else 'FAILED'}")
    
    return "Fixed Health Agent with corrected episodic memory ready"

if __name__ == "__main__":
    main()
